{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYov8eKPSYnqzrWF4GtNEs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DikshantSinghChib/Projects/blob/main/Handwritten_Character_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAWQUMT1guJ8"
      },
      "outputs": [],
      "source": [
        "#https://www.kaggle.com/datasets/suvooo/hindi-character-recognition/data\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/hindi_dataset.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('finish')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "IiDd-pw9hIA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Test Directory\n",
        "train_dir = '/content/DevanagariHandwrittenCharacterDataset/Train'\n",
        "test_dir = '/content/DevanagariHandwrittenCharacterDataset/Test'"
      ],
      "metadata": {
        "id": "dBUYxe-DhKoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of classes in the dataset\n",
        "classes = os.listdir(train_dir)\n",
        "print(len(classes))\n",
        "classes"
      ],
      "metadata": {
        "id": "XF4X96-YhP5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Load image\n",
        "img = mpimg.imread('/content/DevanagariHandwrittenCharacterDataset/Train/character_10_yna/10542.png')\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x5n7J3oThVlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "img = mpimg.imread('/content/DevanagariHandwrittenCharacterDataset/Train/character_10_yna/10576.png')\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y--JvTYNhYc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "img = mpimg.imread('/content/DevanagariHandwrittenCharacterDataset/Train/character_20_na/11061.png')\n",
        "\n",
        "# Display image\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tH4KjvVdhghu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_character = 'ञ ट ठ ड ढ ण त थ द ध क न प फ ब भ म य र ल व ख श ष स ह ॠ त्र ज्ञ ग घ ङ च छ ज झ ० १ २ ३ ४ ५ ६ ७ ८ ९'.split()"
      ],
      "metadata": {
        "id": "iL3-Spa7hkzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating Class label\n",
        "# The names of each character, in the correct order for the Hindi Devnagri script\n",
        "class_names='''character_1_ka character_2_kha character_3_ga character_4_gha character_5_kna character_6_cha character_7_chha\n",
        "character_8_ja character_9_jha character_10_yna character_11_taamatar character_12_thaa character_13_daa character_14_dhaa\n",
        "character_15_adna character_16_tabala character_17_tha character_18_da character_19_dha character_20_na character_21_pa\n",
        "character_22_pha character_23_ba character_24_bha character_25_ma character_26_yaw character_27_ra character_28_la\n",
        "character_29_waw character_30_motosaw character_31_petchiryakha character_32_patalosaw character_33_ha character_34_chhya\n",
        "character_35_tra character_36_gya digit_0 digit_1 digit_2 digit_3 digit_4 digit_5 digit_6 digit_7 digit_8 digit_9'''.split()\n",
        "\n",
        "hindi_character = 'ञ ट ठ ड ढ ण त थ द ध क न प फ ब भ म य र ल व ख श ष स ह ॠ त्र ज्ञ ग घ ङ च छ ज झ ० १ २ ३ ४ ५ ६ ७ ८ ९'.split()"
      ],
      "metadata": {
        "id": "5ukfjW38hrjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Batches\n",
        "\n",
        "#Import the data from the directories, then transform them into batches\n",
        "training_dataset = image_dataset_from_directory(directory=train_dir,\n",
        "                                                image_size=(32,32),\n",
        "                                                batch_size=32,\n",
        "                                                label_mode='categorical')\n",
        "\n",
        "testting_dataset = image_dataset_from_directory(directory=test_dir,\n",
        "                                                image_size=(32,32),\n",
        "                                                batch_size=32,\n",
        "                                                label_mode='categorical',\n",
        "                                                shuffle=False)"
      ],
      "metadata": {
        "id": "RNPLbJN1h2QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Architechture of the CNN\n",
        "\n",
        "model = tf.keras.Sequential([layers.Rescaling(1./255),])\n",
        "\n",
        "#Layer1----------------------------------------------------------\n",
        "model.add(Convolution2D(filters = 32,\n",
        "\t\t\tkernel_size = (3,3),\n",
        "\t\t\tstrides = 1,\n",
        "\t\t\tactivation = \"relu\",\n",
        "\t\t\tinput_shape = (32,32,3)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),\n",
        "\t\t\tstrides=(2, 2),\n",
        "\t\t\tpadding=\"same\"))\n",
        "\n",
        "#Layer2-------------------------------------------------------------\n",
        "model.add(Convolution2D(filters = 32,\n",
        "\t\t\tkernel_size = (3,3),\n",
        "\t\t\tstrides = 1,\n",
        "\t\t\tactivation = \"relu\",\n",
        "\t\t\tinput_shape = (32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),\n",
        "\t\t\tstrides=(2, 2),\n",
        "\t\t\tpadding=\"same\"))\n",
        "\n",
        "\n",
        "#Layers 3-----------------------------------------------------------\n",
        "model.add(Convolution2D(filters = 64,\n",
        "\t\t\tkernel_size = (3,3),\n",
        "\t\t\tstrides = 1,\n",
        "\t\t\tactivation = \"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),\n",
        "\t\t\tstrides=(2, 2),\n",
        "\t\t\tpadding=\"same\"))\n",
        "\n",
        "\n",
        "#Layer 4--------------------------------------------------\n",
        "model.add(Convolution2D(filters = 64,\n",
        "\t\t\tkernel_size = (3,3),\n",
        "\t\t\tstrides= 1,\n",
        "\t\t\tactivation = \"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),\n",
        "\t\t\tstrides=(2, 2),\n",
        "\t\t\tpadding=\"same\"))\n",
        "model.add(Flatten())\n",
        "\n",
        "#Fully Connected Layer 1----------------\n",
        "model.add(Dense(128,\n",
        "\t\tactivation = \"relu\",\n",
        "\t\tkernel_initializer = \"uniform\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Fully Connected Layer 2----------------\n",
        "model.add(Dense(64,\n",
        "\t\tactivation = \"relu\",\n",
        "\t\tkernel_initializer = \"uniform\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Fully Connected Layer 3----------------\n",
        "model.add(Dense(46,\n",
        "\t\tactivation = \"softmax\",\n",
        "\t\tkernel_initializer = \"uniform\"))"
      ],
      "metadata": {
        "id": "WH7XZorfh400"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Model\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = 'adam',\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "fgO8FeVRh-eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model fitting on the loaded dataset\n",
        "model_history = model.fit(training_dataset,\n",
        "                              validation_data = testting_dataset,\n",
        "                        epochs = 25,)"
      ],
      "metadata": {
        "id": "itAAuo1riEXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "test_img = cv2.imread(\"/content/DevanagariHandwrittenCharacterDataset/Test/digit_3/12594.png\")\n",
        "plt.imshow(test_img)\n",
        "test_img = cv2.resize(test_img,(32,32))\n",
        "test_input = test_img.reshape((1,32,32,3))\n",
        "model.predict(test_input)\n",
        "predicted_probability = model.predict(test_input , verbose=1)\n",
        "predicted_class = predicted_probability.argmax(axis=1)\n",
        "class_number = predicted_class[0]\n",
        "print(\"Actual_class : ३\")\n",
        "print(\"Predicted Class : \" ,hindi_character[class_number])"
      ],
      "metadata": {
        "id": "Xdsde245iHao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_2 = test_img = cv2.imread(\"/content/DevanagariHandwrittenCharacterDataset/Test/character_9_jha/12230.png\")\n",
        "plt.imshow(test_img_2)\n",
        "test_img_2 = cv2.resize(test_img_2,(32,32))\n",
        "test_input = test_img_2.reshape((1,32,32,3))\n",
        "model.predict(test_input)\n",
        "predicted_probability = model.predict(test_input , verbose=1)\n",
        "predicted_class = predicted_probability.argmax(axis=1)\n",
        "class_number = predicted_class[0]\n",
        "print(\"Actual_class : ड\")\n",
        "print(\"Predicted Class : \" ,hindi_character[class_number])"
      ],
      "metadata": {
        "id": "c4eANQwuiK_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}